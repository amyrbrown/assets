Hi everyone,

I've spoken to a couple of engineers here at Mozilla about how to
capture the process and the review, and to Prof. Marian Petre at the
Open University about assessment --- she has a world-class reputation
doing empirical research in software engineering, particularly
observational work like this.  Based on those discussions, I'd like to
propose that:

1. Mozilla sets up an instance of a simple code review tool called
   ReviewBoard at http://review.software-carpentry.org

   * We'll require passwords to log in to ReviewBoard, so that only
     participants in the pilot will be able to see stuff.  However,
     authors and reviewers _will_ be able to see each other's code and
     reviews.

   * We will brainstorm with Marian about what data we ought to collect
     that ReviewBoard doesn't already gather.  If there is any, and if
     we can throw together a small plugin to collect it, we'll do that
     before inviting submissions.

2. PLOS contacts the authors of 40-50 papers published in the last 12
   months and invites them to take part in the pilot (wording at the
   end of this message).  We'll start accepting code and doing reviews
   in the first week of August.

3. Authors email their code to review@software-carpentry.org, and we
   add it to a version control repository.  (Normally, we'd just point
   ReviewBoard at the authors' code repository, but if we require that
   for the pilot, we'll bias selection toward the most competent
   participants.)

4. We match code to volunteer reviewers.  We'll aim for first-come,
   first-served, but it will also depend on which reviewers feel they
   can understand what.

5. As each review is completed, we mail authors to let them know where
   the review is, and ask for their feedback on the review.  They can
   provide this by adding comments of their own through ReviewBoard,
   or by sending us notes by email --- we prefer the former, since
   it's the normal workflow, but we'll accept the latter for the
   pilot.

6. We'll turn off the taps at the end of August, then do interviews
   with authors and reviewers in the first half of September by email
   and phone to supplement whatever we've been able to collect through
   ReviewBoard.

As a rough timeline, we'd like to sign off on this in the first week
of July, get invitations out to scientists starting mid-month, start
collecting papers at the beginning of August, and wrap up the reviews
no later than the end of August, so that we can deliver the evaluation
by the end of September.

Please let us know what you think,
Thanks,
Greg Wilson

------------------------------------------------------------

Dear author,

In partnership with the Mozilla Science Lab, the Public Library of
Science (PLOS) is launching a pilot project to explore what code
review could and should look like for research.  During August and
early September, a dozen Mozilla developers will each review three or
four small programs used to produce results in papers published over
the past 12 months.  From this, we hope to learn:

1. How much scientific software can be reviewed by non-specialists,
   and how often is domain expertise required?

2. How much effort does this take compared to reviews of other kinds
   of software, and to reviews of papers themselves?

3. How useful do scientists find these reviews?

We expect to complete and return reviews by the first week of
September, and hope to publish a summary of our results in 2014.

If you would like to take part in this program, we invite you to
submit any piece of software that:

* you wrote yourself to produce a result in a recently-published
  paper;

* is 50-200 lines long; and

* is written in Perl, Python, R, C/C++, or Java.

We will make this code available to the reviewers, and to the
researcher who is monitoring the pilot.  If your code is chosen for
review, we will ask you to subsequently give us up to half an hour of
your time for an interview by email or phone so that we can learn more
about how and whether to take this forward.  If you wish to withdraw
at any time, for any reason, you may do so; we will then remove your
code and our reviews of it from our system, and not include it in our
analysis or results.

Please note: this is only a pilot, and will not affect the status of
your published paper in any way.

If you'd like to take part in this pilot study, please contact us by
email at science-code-review@software-carpentry.org.
